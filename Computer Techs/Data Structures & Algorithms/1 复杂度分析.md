# 1.1 复杂度分析（上）：如何分析代码的执行效率和资源消耗

## 1.1.1 复杂度分析的意义

通过运行代码来统计复杂度的方法被称为事后统计法，这种方法实际上有很大的局限性：

1. 测试结果受测试环境的影响很大
2. 测试结果受测试数据的影响很大

## 1.1.2 大O复杂度表示法

以求1~n的累加和的代码为例，来看如何估算代码的执行时间。

```c++
int cal(int n) {
    int sum = 0;
    int i = 1;
    for(; i<=n; ++i) {
        sum = sum + i;
    }
    return sum;
}
```

可以假设每一条语句的执行时间都是unit_time，那么这段代码总的执行时间就是$(2n+3)\times unit\_time$。

通过这个例子，可以得到一个规律：一段代码总的执行时间T(n)与每一条语句的执行次数成正比。

按照这个思路再来看另一段代码。

```c++
int cal(int n) {
    int sum = 0;
    int i = 1;
    int j = 1;
    for(; i<=n; ++i) {
       j = 1;
       for(; j<=n; ++j) {
           sum = sum + i*j;
       }
    }
}
```

显而易见，这段代码总的执行时间$T(n)=(2n^2+2n+3)\times unit\_time$。

通过这两个例子可以总结出一条重要的规律是：一段代码的执行时间T(n)与每一条语句总的执行次数成正比。

将该规律总结成公式即：
$$
T(n)=O(f(n))
$$
套用这个大O表示法，第一个例子中$T(n)=O(2n+3)$，第二个例子中$T(n)=O(2n^2+2n+3)$。

实际上，大O时间复杂度并不具体表示代码真正的执行时间，而是表示代码执行时间随着数据规模增大的变化趋势，因此也成为**渐进时间复杂度（asymptotic time complexity）**，简称**时间复杂度**。

当n很大时，公式中的低阶、常量、系数三部分并不左右增长趋势，可以将它们忽略。如第二个例子的时间复杂度可以记为$T(n)=O(n^2)$。

## 1.1.3 时间复杂度分析方法

### 加法法则

> 代码总的复杂度等于量级最大的那段代码的复杂度

在分析一段代码的时间复杂度时，只需要关注循环执行次数最多的那段代码。

用公式表示为：

如果
$$
T1(n)=O(f(n));\quad T2(n)=O(g(n)) 
$$
那么
$$
T(n)=T1(n)+T2(n)=max(O(f(n),O(g(n)))=O(max(f(n),g(n)))
$$

### 乘法法则

> 嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

如果
$$
\quad T1(n)=O(f(n)); \quad T2(n)=O(g(n)) 
$$
那么
$$
T(n)=T1(n)\times T2(n)=O(f(n)\times g(n))
$$

## 1.1.4 几种常见的时间复杂度量级

> 常见的时间复杂度量级

- 常量阶 $O(1)$
- 指数阶 $O(2^n)$
- 对数阶 $O(logn)$
- 阶乘阶 $O(n!)$
- 线性阶 $O(n)、O(m+n)$
- 线性对数阶 $O(nlogn)$
- 平方阶 $O(n^2)$
- 立方阶 $O(n^3)$

### $O(1)$

只要代码的执行时间不随数据规模n变化，代码就是常量级时间复杂度，统一记作$O(1)$。

### $O(logn)、O(nlogn)$

用一段代码举例。变量$i$从1开始取值，每循环一次就乘以2，直到$i$大于n时结束循环。

```c++
i = 1;
while(i <= n) {
    i = i * 2;
}
```

实际上$i$的取值是一个等比数列：$2^0,2^1,2^2,…2^x$，当$2^x>n$时，循环结束。可以求出$x=log_2n$，根据对数的换底公式，$log_3n=long_32 \times log_2n$，则$O(log_3n)=O(C\times log_2n)$，其中$C=log_32$是一个常量。根据前面的结论，可以将常量忽略，得到$O(log_2n)=O(log_3n)$。因此，对于对数阶时间复杂度，忽略对数的底，统一表示为$O(logn)$。

$O(nlogn)$就是一段时间复杂度为$O(logn)$的代码被循环执行n遍，这样的代码时间复杂度就是$O(nlogn)$。

### $O(m+n)$

这是一种特殊情况，代码的时间复杂度由两个数据规模来决定，用如下代码举例。

```c++
int cal(int m, int n) {
	int sum_1 = 0;
    int i = 1;
    for(; i <= m; ++i) {
        sum_1 = sum_1 + i;
    }
    int sum_2 = 0;
    int j = 1;
    for(; j <= n; ++j) {
        sum_2 = sum_2 + j;
    }
    return sum_1 + sum_2;
}
```

对于m和n，无法事先评估谁的量级更大，因此在表示时间复杂度时，不能省略其中任何一个。

## 1.1.5 空间复杂度分析

空间复杂度的全称是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。通过一段代码来解释。

```java
public void reverse(int a[], int n) {
    int tmp[] = new int[n];
    for (int i = 0; i < n; ++i) {
		tmp[i] = a[n-i-1];
    }
    for(int i = 0; i < n; ++i) {
        a[i] = tmp[i];
    }
}
```

在第三行代码中申请了一个空间来存储变量$i$，但是它是常量阶的，与数据规模n没有关系，所以在用大O表示法时可以将其忽略。在第二行代码中，申请了一个大小为n的int型数组，因此整段代码的空间复杂度就是$O(n)$。

# 1.2 复杂度分析（下）：详解最好、最坏、平均、均摊这4种时间复杂度

## 1.2.1 最好时间复杂度和最坏时间复杂度

```java
int find(int[] array, int n, int x) {
    int i = 0;
    int pos = -1;
    for(; i < n; ++i) {
        if(array[i] == x) pos = i;
    }
    return pos;
}
```

这段代码的功能是在一个无序的数组中，查找x出现的位置。很明显，时间复杂度为$O(n)$，n为数组的长度。

但实际上在一个数组中查找某个数时不一定要把整个数组都遍历一遍，而是如果在中途找到目标就结束遍历，于是可以对上述代码进行优化。

```java
int find(int[] array, int n, int x) {
    int i = 0;
    int pos = -1;
    for(; i < n; ++i) {
        if(array[i] == x) {
        	pos = i;
            break;
        }
    }
    return pos;
}
```

对于优化过后的代码，其时间复杂度就不只是$O(n)$这么简单了，因为要查找的数据x在数组中的位置不同的情况下，代码的时间复杂度是不一样的。

在最好的情况下，数据x刚好是数组的第一个元素，这时的时间复杂度为$O(1)$，将其称为**最好时间复杂度**。

在最坏的情况下，数据x是数据的最后一个元素或不存在于数组中，这时的时间复杂度就为$O(n)$，将其称为**最坏时间复杂度**。

## 1.2.2 平均时间复杂度

因为最好时间复杂度和最坏时间复杂度这两种情况都比较极端，发生的概率很小，于是引入平均时间复杂度来表示平均情况下的复杂度。

**平均时间复杂度**指的是代码被重复执行无数次，对应的时间复杂度的平均值。

依然以上述代码为例，要查找的数据在数组中的位置一共有n+1种情况：在0~n-1位置上和不在数组中，把每种情况下需要遍历的元素个数累加，再除以n+1就得到了需要遍历的元素个数的平均值即
$$
{1+2+3+\cdots+n+n\over n+1}=\frac{n(n+3)}{2(n+1)}
$$
将系数、低阶、常量省略后，得到平均情况时间复杂度为$O(n)$。

虽然结论是正确的，但是计算的过程有些问题，因为这n+1种情况出现的概率并不相同。

显然，要查找的数据x要么在数组中，要么不在数组中，两种情况出现的概率都是$\frac12$。另外，x在数组中出现在0~n-1这n个位置的概率都是$\frac1n$。根据概率乘法法则，要查找的数据出现在0~n-1中任意位置的概率是${1\over 2n}$。于是，重新计算平均时间复杂度为
$$
1\times{1\over 2n}+2\times{1\over 2n}+3\times{1\over 2n}+\cdots+n\times{1\over 2n}+n\times \frac12={3n+1\over 4}
$$
这个值就是概率论中的加权平均值，也称期望值。因此，平均时间复杂度更准确的描述应该是加权平均时间复杂度或期望时间复杂度。用大O表示法来表示，去掉系数和常量，结果还是$O(n)$。

在多数情况下并不需要区分这三种时间复杂度，只有当同一段代码在不同情况下的性能表现不同，并且时间复杂度有量级差别时，才会使用这三种复杂度来表示。

### 1.2.3 均摊时间复杂度

均摊时间复杂度是平均时间复杂度的一种特种情况，使用摊还分析法进行分析。

```java
int[] array = new int[n];
int count = 0;
void insert(int val) {
    if(count == array.length) {
        int sum = 0;
        for(int i = 0; i < array.length; ++i) {
            sum = sum + array[i];
        }
        System.out.println(sum);
    	count = 0;
    }
    array[count] = val;
    ++count;
}
```

在最好的情况下，数组中有未占用的空间，直接将数据插入到数组下标为count的位置即可，时间复杂度为$O(1)$

在最坏的情况下，数组中没有未占用的空间，此时需要先将数组遍历一遍求和，再将数据插入，时间复杂度为$O(n)$。

对于平均时间复杂度，上述代码执行时共有n+1种情况。当数组中有未占用空间时，根据数据插入位置的不同，分为n种情况；当数组中无未占用空间时，插入数据需要先遍历数组。这n+1种情况发生的概率均为$\frac{1}{n+1}$，根据加权平均值的计算方法，平均时间复杂度为
$$
1\times{1\over n+1}+1\times{1\over n+1}+\cdots+1\times{1\over n+1}+n\times{1\over n+1}=O(n)
$$
但是对于insert函数的平均时间复杂度分析不需要这么复杂，和前面的find函数对比一下会发现两者的差异如下。

- find函数在极端情况下，时间复杂度才为$O(1)$，而insert函数在大部分情况下，时间复杂度为$O(1)$，只有在一种情况下复杂度才比较高，为$O(n)$。
- 对于insert函数，时间复杂度为$O(1)$和$O(n)$出现的频率是非常有规律的，有一定的前后时序关系，一般是在一个$O(n)$时间复杂度的插入后，紧跟n-1个$O(1)$时间复杂度的插入，如此循环。

针对这样的特殊情况，我们可以使用更简单的方法来分析时间复杂度，即摊还分析法，得出的时间复杂度称为**均摊时间复杂度**。

我们把耗时多的那次操作的耗时均摊到接下来的n-1次耗时少的操作上，那么这一组连续插入操作的时间复杂度就是$O(1)$。