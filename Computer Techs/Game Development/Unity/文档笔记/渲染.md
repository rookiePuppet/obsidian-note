# 渲染管线

Unity每渲染一帧时，都会重复执行这几个步骤。

1. 剔除。决定哪些物体能够被显示，通常会移除摄像机视野外的物体。
2. 渲染。将物体以正确的光照渲染成屏幕上的像素。
3. 后处理。对像素进一步处理，产生最终的屏幕图像输出。

Unity提供3种不同的预制渲染管线，根据兼容性和性能来考虑选择，也可以创建自己的渲染管线。

## 可编程渲染管线基础

[可编程渲染管线（SRP）](https://docs.unity3d.com/Packages/com.unity.render-pipelines.core@17.0/manual/index.html)是一个精简的API层，让我们能够使用C#来配置渲染指令，这些指令会被传送到Unity的底层图形架构，最后由图形API来执行。

URP和HDRP都是基于SRP的，你也可以基于SRP创建自己的管线。

基于SRP的渲染管线都有两个关键的定制要素：**渲染管线实例**和**渲染管线资产**。

- 渲染管线实例：定义了渲染管线功能的类（继承于RenderPipeline，重写了Render方法）的实例。
- 渲染管线资产：存储了关于如何使用渲染管线实例以及如何配置的数据，继承于RenderPiplelineAsset，重写了CreatePipeline方法。

[RenderPipelineContext](https://docs.unity3d.com/Packages/com.unity.render-pipelines.core@17.0/manual/srp-using-scriptable-render-context.html)是一个类，提供使用C#代码访问Unity底层图形API的能力。

## 如何选择渲染管线

[Unity - Manual: Choosing a render pipeline](https://docs.unity3d.com/6000.0/Documentation/Manual/choose-a-render-pipeline-landing.html)

## 渲染路径

渲染路径是将摄像机所看到的游戏对象绘制出来并提供照明的一系列操作。

#### Forward

前向渲染是Unity中默认的渲染路径，其按以下方式工作：

- 逐一点亮每一个游戏对象。
- 对于照明的频率和质量是有限制的，并且在不同的渲染管线中会有所区别。

内置渲染管线中还有顶点照明渲染路径，是前向渲染的子集。

#### Deferred

- Unity首先会创建一个几何缓冲区(G-Buffer)，G-Buffer是一个存储摄像机所使用的关于几何和材质数据的纹理集合。
- Unity使用G-Buffer中的数据一次性将所有游戏对象点亮。
- 由于在照明上的限制更少，游戏对象和阴影的渲染会有更多细节。

延迟渲染路径不能渲染透明物体，因此Unity会在该渲染路径执行结束时使用一个前向渲染的通道来渲染透明物体。

> 对玩家系统的要求

Deferred渲染路径对玩家系统的要求和限制如下：

- 支持最小的Shader Model版本是4.5
- 不支持Open GL和Open GL ES的API

> 每个摄像机可见的光源限制

所有的渲染路径都有可见光源数量的限制。

对于Forward和Deferred渲染路径：

- 桌面和主机平台：1个主光源，256个额外光源
- 移动平台：一个主光源，32个额外光源。OpenGL ES 3.0和更早的版本：一个主光源，16个额外光源

对于Forward+渲染路径，以相同方式处理所有的光源，因此比Forward和Deferred要少一个光源。

#### 设置渲染路径

在渲染器资产文件中，Lighting > Rendering Path 可以选择渲染路径。

## 通用渲染管线

### 基础概念

URP使用以下组件渲染场景：

- URP渲染器：包括通用渲染器和2D渲染器
- URP着色器的着色模型
- 摄像机
- URP资产

下图展示了URP通用渲染器的帧渲染循环。

![[Pasted image 20241104193916.png]]

URP渲染器会为场景上的每一个摄像机执行Camera Loop。

- 设置剔除参数：配置剔除系统如何剔除灯光和阴影的相关参数。
- 剔除：使用剔除参数计算出可见的渲染器、阴影转换器和摄像机可见的灯光。剔除参数和摄像机层距离会影响剔除和渲染的性能。
- 构建渲染数据：获取基于剔除结果、品质设置、摄像机和当前平台的信息，构建出渲染数据。渲染数据用来告诉渲染器，当前摄像机和运行平台需要的渲染操作和渲染质量。
- 设置渲染器：构建一系列渲染器通道，加入渲染队列。
- 执行渲染器：根据渲染数据来按队列顺序依次执行，渲染器会在帧缓冲区输出摄像机图像。

#### 渲染路径

在URP中可以选择三种渲染路径：

- Forward
- Forward+
- Deferred

渲染路径会影响Unity对物体的绘制和照明， 从而影响渲染的结果和耗时。


### 配置URP以获得更好的性能

根据项目和目标平台，以下方面可能对性能影响最大：

- 选择的渲染路径
- URP使用的内存容量
- CPU处理时间
- GPU处理时间

#### 减少URP使用的内存

在URP资产中做以下事情：

- 禁用深度纹理
- 禁用不透明纹理
- 禁用渲染层(Deferred)，这样URP不会创建额外的渲染目标
- 禁用HDR，如果要使用，则将精度设置为32bit
- 降低阴影分辨率，Main Light > Shadow Resolution，Additional Lights > Shadow Atlas Resolution
- 禁用Light Cookies，或降低Cookies Resolution 和 Cookies Atlas Format
- 在低端设备上，设置Store Actions为Auto或Discard

在URP渲染器资产中，可以设置Intermediate Texture为Auto，以减少使用的GPU带宽。

[Unity - Manual: Configure for better performance in URP](https://docs.unity3d.com/6000.0/Documentation/Manual/urp/configure-for-better-performance.html)

#### 减少CPU处理时间

在URP资产中做以下事情：

- 设置Volume Update Mode为Via Scripting，这样URP就不会每帧更新volume，但是需要你通过API（例如UpdateVolumeStack）手动更新。
- 在低端设备上，如果使用反射探针，则禁用Probe Blending和Box Projection。
- 在Shadows部分，禁用Max Distance，使URP在阴影通道处理更少的物体。
- 在Shadows部分，禁用Cascade Count，减少渲染通道数量。
- 在Additional Lights部分，禁用Cast Shadows。

因为场景中每一个摄像机都需要给URP的剔除和渲染工作提供资源，所以尽量减少摄像机的使用数量。

#### 减少GPU处理时间

在URP资产中做以下事情：

- 降低或禁用Anti-aliasing（MSAA）
- 禁用Terrain Holes
- 启用SRP Batcher，这样URP可以降低Draw Call之间的GPU设置时间，并让材质数据在显存中持久化。
- 在低端移动平台，禁用LOD Cross Fade，这样URP就不会使用alpha测试来让LOD网格淡入淡出。
- 设置Additional Lights为Disabled，或者Per Vertex（Forward路径）。
- 禁用Soft Shadows，或降低其品质。

在Universal Renderer资产中：

- 若使用Vulkan，Metal 或 DX12，启用Native RenderPass
- 若使用Forward或Forward+路径，在主机和PC平台上设置Depth Priming Mode为Auto或Forced，在移动平台上将其禁用。
- 设置Depth Texture Mode为After Transparents，可以避免URP在透明和不透明通道之间切换渲染目标。

还可以：

- 避免使用Complex Lit shader，它有非常复杂的光照计算。如果要使用，则禁用Clear Coat。
- 在低端移动平台，对静态物体使用Baked Lit shader，对动态物体使用Simple Lit shader。
- [使用SSAO时的设置](https://docs.unity3d.com/6000.0/Documentation/Manual/urp/post-processing-ssao.html)。

### 自定义渲染和后处理

可编程渲染通道是一种改变Unity如何渲染场景的方式，通过插入一个渲染通道到渲染管线中可以实现自定义的视觉效果。

可编程渲染通道能做什么：

- 改变场景中材质的属性
- 改变Unity渲染游戏对象的顺序
- 让Unity读取摄像机缓存以在Shader中使用

例如，可以使用可编程渲染通道实现在显示游戏菜单时模糊摄像机的画面。

Unity会在URP渲染循环期间将渲染通道注入到的特定位置，这些位置称为注入点。通过设置不同的注入点，可以控制渲染通道如何影响场景的渲染结果。

#### 通过可编程渲染通道添加预构建效果

Unity在DrawOpaqueObjects和DrawTransparentObjects通道中绘制物体，而你可能需要在帧渲染当中的不同位置绘制物体，或者以其他方式解释和写入渲染数据（比如深度和模板）。

使用Render Objects Renderer Feature就可以在特定的层级、特定的事件、使用特定的覆盖来绘制物体，以完成这种自定义的需求。

[Unity - Manual: Add a Renderer Feature to a URP Renderer](https://docs.unity3d.com/6000.0/Documentation/Manual/urp/urp-renderer-feature.html)

##### 通过Render Objects渲染器特性创建自定义的渲染效果

URP在**DrawOpaqueObjets**和**DrawTransparentObjects**通道中绘制对象。

利用Renderer Feature中的Render Objects可以在帧渲染的不同位置、特定层级和时间绘制对象，以及写入渲染数据（例如深度和模板）。

#### 自定义渲染通道流程

自定义渲染通道是一种改变渲染管线如何渲染场景和物体的方法，它包含了你自己写的插入到某一个注入点的渲染代码。

添加一个自定义的渲染通道：

1. 使用Scriptable Render Pass的API编写自定义渲染通道的代码。
2. 通过创建一个Scriptable Renderer Feature，或使用RenderPipelineManager的API，将自定义渲染通道添加到URP的帧渲染循环中。

> 为自定义渲染通道编写代码

创建一个继承于ScriptableRenderPass的类，在其中使用render graph的API告诉Unity要使用什么纹理和渲染目标以及在上面做什么操作。

> 创建Scriptable Render Feature

为了将渲染通道添加到渲染循环，创建一个继承于ScriptableRendererFeature的类，这个类用于：

1. 创建自定义渲染通道的实例
2. 将自定义渲染通道插入到渲染管线中

另外也可以通过订阅RenderPipelineManager中的事件来添加渲染通道。

#### URP中的Blit

使用可编程渲染管线核心中的Blitter API，可以在一个自定义的渲染通道中将一张纹理的数据传送到另一张纹理。

> Blit的解释：A shorthand term for “bit block transfer”. A blit operation is the process of transferring blocks of data from one place in memory to another.

使用Blitter API的Shader必须手写，Shader Graph并不兼容Biltter API。

注：不要使用CommandBuffer.Blit或Graphics.Blit或在内部使用了它们的API，例如RenderingUtils.Blit，因为这些API可能会打断XR的渲染，并且不兼容原生的渲染通道。

#### 渲染图系统

Render graph system是一个用来创建可编程渲染通道（Scriptable Render Pass）的API集合。

当使用render graph API来创建可编程渲染通道时，就是告诉URP做以下事情：

1. 要使用的纹理或渲染纹理，该阶段是一个记录阶段
2. 要执行的图形命令，并使用来自上一阶段的纹理或渲染纹理，该阶段是执行阶段。

接下来就可以将可编程渲染通道添加到URP渲染器中了，可编程渲染通道会变成URP内部渲染图的一部分，即URP每帧都会按步骤执行的一个渲染通道序列。URP会自动优化这些渲染通道和渲染图，以最小化渲染通道的数量，以及所使用的内存和带宽。

> URP如何优化渲染

- 避免分配帧当中不使用的资源
- 如果最终帧不使用某个渲染通道的输出，则将它们移除
- 优化GPU内存，例如重复利用已分配的资源
- 自动同步计算和图形GPU命令队列

对于使用基于块的延迟渲染，URP也可以将多个渲染通道合并为一个单独的原生渲染通道。原生渲染通道会保持纹理数据在内存块中，而不是将纹理从GPU拷贝到CPU，因此URP能使用更少的内存带宽和渲染时间。

#### 使用渲染图系统编写渲染通道

> 声明一个渲染通道

即声明一个继承于ScriptableRenderPass的类。

> 声明渲染通道使用的资源

在渲染通道内部声明一个包含需要使用的资源的类，以便渲染图系统在渲染代码执行期间访问这个数据结构。资源可以是常规的C#变量和渲染图资源引用，确保仅声明了渲染通道需要使用的变量，增加不必要的变量会降低性能。

RecordRenderGraph方法用于填充数据，然后渲染图会将数据作为一个参数传递到渲染方法中。

> 声明为渲染通道生成渲染命令的渲染方法

如下，RecordRenderGraph方法会通过`SetRenderFunc`命令渲染图使用这个的方法。

```C#
static void ExecutePass(PassData data, RasterGraphContext context)
{
    // Records a rendering command to copy, or blit, the contents of the source texture
    // to the color render target of the render pass.
    // The RecordRenderGraph method sets the destination texture as the render target
    // with the UseTextureFragment method.
    Blitter.BlitTexture(context.cmd, data.copySourceTexture,
        new Vector4(1, 1, 0, 0), 0, false);
}
```

> 实现RecordRenderGraph方法

利用RecordRenderGraph方法在渲染图系统中添加并配置一个或多个渲染通道。

Unity会在渲染图配置步骤中调用这个方法，并使你能够为渲染图的执行注册相关的通道和资源，从而实现自定义渲染。

在RecordRenderGraph方法中可以声明渲染通道的输入和输出，但不要添加命令到命令缓冲区。

 > 渲染图builder变量和帧资源
 
 builder变量是IRasterRenderGraphBuilder结构的一个实例，也是配置渲染通道相关信息的入口。

UniversalResourceData类包含了URP使用的所有纹理资源，包括摄像机的激活颜色和深度纹理。

UniversalCameraData类包含了和当前激活的摄像机相关的数据。

下面的样例创建了一个临时目标纹理，UniversalRenderer.CreateRenderGraphTexture是一个辅助方法，其调用了RenderGraph.CreateTexture方法。

```C#
TextureHandle destination = UniversalRenderer.CreateRenderGraphTexture(renderGraph, desc, "CopyTexture", false);
```

builder.UseTexture方法声明了这个渲染通道使用源纹理作为一个只读输入。

```CS
builder.UseTexture(passData.copySourceTexture);
```

在这个例子中，builder.SetRenderAttachment方法声明了这个渲染通道使用临时的目标纹理作为它的颜色渲染目标，和cmd.SetRenderTarget（非渲染图API）类似。

SetRenderFunc方法设置ExecutePass方法作为渲染图在执行渲染通道时调用的渲染方法，样例中使用了一个lambda表达式来避免内存分配。

```CS
builder.SetRenderFunc((PassData data, RasterGraphContext context) => ExecutePass(data, context));
```

> RecordRenderGraph方法的完整代码

```CS
// This method adds and configures one or more render passes in the render graph.
// This process includes declaring their inputs and outputs,
// but does not include adding commands to command buffers.
public override void RecordRenderGraph(RenderGraph renderGraph, ContextContainer frameData)
{
    string passName = "Copy To Debug Texture";

    // Add a raster render pass to the render graph. The PassData type parameter determines
    // the type of the passData output variable.
    using (var builder = renderGraph.AddRasterRenderPass<PassData>(passName,
        out var passData))
    {
        // UniversalResourceData contains all the texture references used by URP,
        // including the active color and depth textures of the camera.
        UniversalResourceData resourceData = frameData.Get<UniversalResourceData>();

        // Populate passData with the data needed by the rendering function
        // of the render pass.
        // Use the camera's active color texture
        // as the source texture for the copy operation.
        passData.copySourceTexture = resourceData.activeColorTexture;

        // Create a destination texture for the copy operation based on the settings,
        // such as dimensions, of the textures that the camera uses.
        // Set msaaSamples to 1 to get a non-multisampled destination texture.
        // Set depthBufferBits to 0 to ensure that the CreateRenderGraphTexture method
        // creates a color texture and not a depth texture.
        UniversalCameraData cameraData = frameData.Get<UniversalCameraData>();
        RenderTextureDescriptor desc = cameraData.cameraTargetDescriptor;
        desc.msaaSamples = 1;
        desc.depthBufferBits = 0;

        // For demonstrative purposes, this sample creates a temporary destination texture.
        // UniversalRenderer.CreateRenderGraphTexture is a helper method
        // that calls the RenderGraph.CreateTexture method.
        // Using a RenderTextureDescriptor instance instead of a TextureDesc instance
        // simplifies your code.
        TextureHandle destination =
            UniversalRenderer.CreateRenderGraphTexture(renderGraph, desc,
                "CopyTexture", false);

        // Declare that this render pass uses the source texture as a read-only input.
        builder.UseTexture(passData.copySourceTexture);

        // Declare that this render pass uses the temporary destination texture
        // as its color render target.
        // This is similar to cmd.SetRenderTarget prior to the RenderGraph API.
        builder.SetRenderAttachment(destination, 0);

        // RenderGraph automatically determines that it can remove this render pass
        // because its results, which are stored in the temporary destination texture,
        // are not used by other passes.
        // For demonstrative purposes, this sample turns off this behavior to make sure
        // that render graph executes the render pass. 
        builder.AllowPassCulling(false);

        // Set the ExecutePass method as the rendering function that render graph calls
        // for the render pass. 
        // This sample uses a lambda expression to avoid memory allocations.
        builder.SetRenderFunc((PassData data, RasterGraphContext context)
            => ExecutePass(data, context));
    }
}
```

> 将渲染通道实例注入到渲染器中

使用来自Renderer Feature实现的AddRenderPasses方法，可以将一个可编程渲染通道注入到渲染器。

URP会每帧对每一个摄像机都执行AddRenderPasses方法。

```CS
public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData)
{
    renderer.EnqueuePass(m_CopyRenderPass);
}
```

#### 渲染图中的纹理

##### 创建纹理

在自定义的`ScriptableRenderPass`子类的`RecordRenderGraph`方法中，按以下步骤创建纹理：

1. 创建一个`RenderTextureDescriptor`对象，赋予其需要的纹理属性
2. 使用`UniversalRenderer.CreateRenderGraphTexture`方法创建一个纹理，并返回一个纹理handle。

如下代码创建了一张和屏幕尺寸相同的纹理：

```C#
RenderTextureDescriptor textureProperties = new RenderTextureDescriptor(Screen.width, Screen.height, RenderTextureFormat.Default, 0);
TextureHandle textureHandle = UniversalRenderer.CreateRenderGraphTexture(renderGraph, textureProperties, "My texture", false);
```

之后便可以在同一个自定义的渲染通道中使用该纹理了，并且只有当前摄像机可以访问它。

当URP对渲染图做优化时，如果最终帧没有使用某个纹理，则该纹理不会被创建出来，目的是减少内存和带宽消耗。

渲染图系统会管理使用`CreateRenderGraphTexture`方法创建的纹理的生命周期，因此在你不需要使用它们时也不用手动释放内存。

##### 导入纹理

当使用渲染图系统创建纹理时，纹理会交由渲染图系统进行管理，因此创建出来的纹理在下一帧中可能就不存在了，而其他摄像机或许就无法使用它了。

为了确保纹理在帧和摄像机之间一直处于可用状态，可以使用`ImportTexture`API将纹理导入渲染图系统。

例如可以创建一个渲染纹理，其指向项目中的某个纹理资源，将它作为渲染通道的输入。

渲染图系统不会管理导入纹理的生命周期，因此：

1. 当不再使用导入纹理时，必须处理其相关内存的释放
2. URP无法对使用了导入纹理的渲染通道做剔除，所以渲染会更慢

> 如何导入纹理

在ScriptableRenderPass子类的RecordRenderGraph方法中，按以下步骤导入纹理：

1. 使用`RTHandle`API创建一个渲染纹理句柄
2. 创建`RenderTextureDescriptor`对象，附带需要的纹理属性
3. 使用`ReAllocateIfNeeded`方法创建一个渲染纹理，将其附加到渲染纹理句柄上。该方法仅当渲染纹理句柄为空或渲染纹理和渲染纹理标识符有不同属性时，才会创建一个渲染纹理。
4. 导入纹理，将`RTHandle`对象转换为一个`TextureHandle`对象。

```CS
// 1
private RTHandle renderTextureHandle;

// 2
RenderTextureDescriptor textureProperties = new RenderTextureDescriptor(Screen.width, Screen.height, RenderTextureFormat.Default, 0);

// 3
RenderingUtils.ReAllocateIfNeeded(ref renderTextureHandle, textureProperties, FilterMode.Bilinear, TextureWrapMode.Clamp, name: "My render texture" );

// 4
TextureHandle texture = renderGraph.ImportTexture(renderTextureHandle);
```

> 如何导入来自项目中的纹理

1. 使用`RTHandles.Alloc`API从外部纹理中，创建一个渲染纹理句柄
2. 导入纹理，将将`RTHandle`对象转换为一个`TextureHandle`对象

```CS
// 1
RTHandle renderTexture = RTHandles.Alloc(texture);

// 2
TextureHandle textureHandle = renderGraph.ImportTexture(renderTexture);
```

> 如何处理使用完成的导入纹理

必须在渲染通道的最后释放掉渲染纹理的内存，在Dispose方法中。

```CS
public void Dispose()
{
    renderTexture.Release();
}
```

#### 在渲染通道中使用纹理

必须使用渲染图系统的API将纹理设置为自定义渲染通道的输入或输出，那样才可以对纹理进行数据读取或写入。

##### 设置纹理作为输入

1. 在通道使用的数据结构中添加一个纹理句柄字段
2. 将纹理句柄设置到纹理上
3. 调用`UseTexture`方法将纹理设置为一个输入

```CS
// 1
public class MyPassData
{
    // Add a texture handle
    public TextureHandle textureToUse;
}

// 2
// Add the texture handle to the data
RenderTextureDescriptor textureProperties = new RenderTextureDescriptor(Screen.width, Screen.height, RenderTextureFormat.Default, 0);
TextureHandle textureHandle = UniversalRenderer.CreateRenderGraphTexture(renderGraph, textureProperties, "My texture", false);
passData.textureToUse = textureHandle;

// 3
builder.UseTexture(passData.textureToUse, AccessFlags.Read);
```

之后，在SetRenderFunc方法中就可以使用纹理句柄对象了。

##### 设置纹理作为渲染目标

在RecordRenderGraph方法中使用SetRednerAttachment方法可以将一张纹理作为命令的输出目标，该方法默认将纹理设置为仅写入。

如下命令创建了一张临时纹理，并将它设置为渲染通道的渲染目标。

```CS
// Create texture properties
RenderTextureDescriptor textureProperties = new RenderTextureDescriptor(Screen.width, Screen.height, RenderTextureFormat.Default, 0);

// Create the texture
TextureHandle targetTexture = UniversalRenderer.CreateRenderGraphTexture(renderGraph, textureProperties, "My texture", false);

// Set the texture as the render target
// The second parameter is the index the shader uses to access the texture
builder.SetRenderAttachment(targetTexture, 0);
```

在执行渲染通道之前，渲染图系统会自动设置好纹理，所以你不需要将纹理添加到通道数据当中。

##### 在渲染通道期间改变渲染目标

在渲染图系统的渲染通道期间更改URP写入的纹理，但是可以做以下事情作为替代：

- 创建另一个自定义渲染通道，然后使用`builder.SetRenderAttachment`来更改渲染目标
- 使用`UnsafePass`API，然后在`SetRenderFunc`方法中就可以使用`SetRenderTarget`方法来更改渲染目标了。

如果在多张带有不同属性的纹理之间传图，由于URP不能将blits合并到一个单独的原生渲染通道中，渲染可能会变慢。使用`AddUnSafePass`和`SetRenderTarget`做替代。

#### 获取帧数据

##### 当前帧数据

可以获取URP为当前帧创建的纹理（如颜色缓冲区或G缓冲区纹理），然后在自定义的渲染通道里使用。这些纹理被称为帧数据、资源数据或者帧资源。

```CS
public override void RecordRenderGraph(RenderGraph renderGraph, ContextContainer frameContext)
{
    using (var builder = renderGraph.AddRasterRenderPass<PassData>("Get frame data", out var passData))
    {
        UniversalResourceData frameData = frameContext.Get<UniversalResourceData>();
        
        TextureHandle activeColorTexture = frameData.activeColorTexture;
    }
}
```

获取到的纹理句柄只能在当前的渲染图当前帧中使用，使用`ConfigureInput`API确保URP生成了帧数据中你需要的纹理。

##### 过往帧数据

使用`UniversalCameraData.historyManager`API可以获取摄像机渲染得到的过往帧数据，其中的纹理有时被称为历史纹理或历史缓冲区。

由于过往帧是GPU渲染管线的输出，所以它们不包含任何在GPU渲染之后才处理的内容，例如后处理效果。

```CS
public override void RecordRenderGraph(RenderGraph renderGraph, ContextContainer frameContext)
{
    UniversalCameraData cameraData = frameContext.Get<UniversalCameraData>();
    
    // Request access to the color textures
    // Use `RawDepthHistory` instead to request access to the depth textures.
    cameraData.historyManager.RequestAccess<RawColorHistory>();
    
    // Get the previous textures 
	RawColorHistory history = cameraData.historyManager.GetHistoryForRead<RawColorHistory>();
	
	// Get the first texture, which the camera rendered in the previous frame
	RTHandle historyTexture = history?.GetPreviousTexture(0);
	
	// Convert the texture into a handle the render graph system can use
	passData.historyTexture = renderGraph.ImportTexture(historyTexture);
}
```

#### 在渲染图系统中绘制对象

> 创建绘制对象的列表

1. 在ScriptableRenderPass类的通道数据结构类中，创建一个`RendererListHandle`字段：`private class PassData { public RendererListHandle objectsToDraw; }`
2. 创建一个RendererListParams对象，其包含需要绘制的对象、绘制设定以及剔除数据。
3. 在RecordRenderGraph方法中，使用`CreateRendererList`API将RenderListParams对象转换为一个渲染图系统能够使用的句柄：`RenderListHandle rendererListHandle = renderGraph.CreateRendererList(rendererListParameters);`
4. 设置通道数据中的RendererListHandle对象：`passData.objectsToDraw = rendererListHandle;`

> 绘制对象

1. 在RecordRenderGraph方法中，使用`UseRendererList`API告诉渲染图系统需要绘制的对象列表：`builder.UseRendererList(passData.rendererListHandle);`
2. 设置绘制对象的目标纹理：
```CS
UniversalResourceData frameData = frameContext.Get<UniversalResourceData>(); builder.SetRenderAttachment(frameData.activeColorTexture, 0); builder.SetRenderAttachmentDepth(frameData.activeDepthTexture, AccessFlags.Write);
```
3. 在SetRenderFunc方法中，使用`DrawRendererList`API绘制渲染器：`context.cmd.DrawRendererList(passData.rendererListHandle);`

#### 优化渲染图

要优化渲染图，核心在于合并或者减少渲染通道。

> 使用现有的颜色、深度缓冲

当要使用颜色或深度缓冲时，不要手动拷贝它们，而是使用URP默认创建的拷贝。

使用ConfigureInput来确保URP生成了在帧数据中需要的纹理。

在Render Graph Viewer中可以查看URP的这两个渲染通道：Copy Color和Copy Depth。

> 合并渲染通道

使用Render Graph Viewer来检查URP无法合并渲染通道的原因，在采用tile-based deffered rendering(TBDR)的设备上，合并渲染通道可以降低设备功耗。

确保URP可以合并渲染通道：

- 使用AddRasterRenderPass而非其他类型
- 如果只需要从帧缓冲中读取当前像素而不是相邻像素，就使用`SetInputAttachment`API和`LOAD_FRAMEBUFFER_X_INPUT`宏

> 减少渲染通道的数量

不要为了更少和组织性更好的代码而创建非必要的渲染通道。

使用`AddUnsafePass`API和兼容模式API例如`SetRenderTarget`编写组合的渲染通道，但这样可能会导致渲染变慢，因为URP无法优化该渲染通道。

> 避免在颜色缓冲区上来回Blit

当需要对颜色缓冲区进行处理，再写回颜色缓冲区时，避免创建两个渲染通道，而是使用`ContextContainer`对象直接对颜色缓冲区进行读写。

```CS
public override void RecordRenderGraph(RenderGraph renderGraph, ContextContainer frameData)
{
    // Fetch the frame data textures
    var resourceData = frameData.Get<UniversalResourceData>();
    // Set the source as the color texture the camera currently targets
    var source = resourceData.activeColorTexture;
    // Create a destination texture, with the same dimensions as the source
    var destinationDescriptor = renderGraph.GetTextureDesc(source);
    destinationDescriptor.name = "DestinationTexture";
    destinationDescriptor.clearBuffer = false;
    TextureHandle destination = renderGraph.CreateTexture(destinationDescriptor);
    // Use the AddBlitPass API to create a simple blit from the source to the destination
    RenderGraphUtils.BlitMaterialParameters parameters = new(source, destination, BlitMaterial, 0);
    renderGraph.AddBlitPass(parameters, passName: "MyRenderPass");
    // Set the main color texture for the camera as the destination texture
    resourceData.cameraColor = destination;
}
```

### 添加可编程渲染通道到渲染循环中

#### 通过Scriptable Renderer Feature注入渲染通道

##### 关于Scriptable Renderer Feature

Scriptable Renderer Feature是一种可自定义的Renderer Feature类型，是一种可编程的组件，能够添加到渲染器当中以改变引擎渲染场景和物体的方式。

Scriptable Renderer Feature需要管理多个Scriptable Render Pass，并控制何时以及如何将渲染通道们应用到一个特定的渲染器或摄像机，这让需要多个渲染通道的复杂效果实现变得更加简单。

> Scriptable Renderer Feature还是Scriptable Render Pass

两者都能达到相似的结果，但是在一些情况下也会有优劣之分。

最关键的区别在于工作流，Scriptable Renderer Feature必须添加到渲染器按顺序运行，而Scriptable Render Pass更加灵活但在跨场景应用时需要额外的操作。

Scriptable Renderer Feature适合用于将效果应用到多个摄像机、多个场景或整个项目中，因为当其被添加到渲染器后，所有使用该渲染器的地方都会使用这个Scriptable Renderer Feature。也就是说，只需要对它做一次更改，到处都能生效。

相反地，Scriptable Render Pass通过注入到场景或项目中的某一个位置来添加效果，从而避免编写复杂的脚本以及尽可能减小对性能的影响。

##### 创建Scriptable Renderer Feature

1. 创建C#类，继承自`ScriptableRendererFeature
`
```CS
public class MyRendererFeature : ScriptableRendererFeature { }
```

2. 重写`Create`方法，创建`Scriptable Render Pass`实例，注入到渲染器中

```Cs
// Define an instance of the Scriptable Render Pass
private RedTintRenderPass redTintRenderPass;

public override void Create()
{
    // Create an instance of the Scriptable Render Pass
    redTintRenderPass = new RedTintRenderPass();

    // Inject the render pass after rendering the skybox
    redTintRenderPass.renderPassEvent = RenderPassEvent.AfterRenderingSkybox;
}
```

 Create 方法的执行时机：
 1. 当ScriptableRendererFeature第一次加载时
 2. 当ScriptableRendererFeature启用或禁用时
 3. 当从Renderer Feature的监视窗口修改属性时

3. 重写`AddRenderPasses`方法，使用`EnqueuePass`API将`Scriptable Render Pass`注入渲染循环

```CS
public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData)
{
    renderer.EnqueuePass(redTintRenderPass);
}
```

该方法会在每帧对每一个摄像机调用。

##### 对指定摄像机类型应用Scriptable Renderer Feature

在AddRenderPasses方法中，使用if语句判断摄像机类型，如下：

```CS
if (renderingData.cameraData.cameraType == CameraType.Game)
{
	renderer.EnqueuePass(yourRenderPass);
}
```

#### 通过编写脚本注入渲染通道

在每帧渲染激活的摄像机之前，Unity会发起`beginCameraRendering`事件，通过订阅该事件以在该摄像机被渲染之前执行自定义的逻辑。

> 使用RenderPipelineManager

1. 订阅RenderPipelineManager类中的某个事件
2. 在订阅方法中，使用ScriptableRenderer实例的EnqueuePass方法将自定义的渲染通道注入到URP帧渲染中

```CS
public class EnqueuePass : MonoBehaviour
{
    [SerializeField] private BlurSettings settings;    
    private BlurRenderPass blurRenderPass;

    private void OnEnable()
    {
        ...
        blurRenderPass = new BlurRenderPass(settings);
        // Subscribe the OnBeginCamera method to the beginCameraRendering event.
        RenderPipelineManager.beginCameraRendering += OnBeginCamera;
    }

    private void OnDisable()
    {
        RenderPipelineManager.beginCameraRendering -= OnBeginCamera;
        blurRenderPass.Dispose();
        ...
    }

    private void OnBeginCamera(ScriptableRenderContext context, Camera cam)
    {
        ...
        // Use the EnqueuePass method to inject a custom render pass
        cam.GetUniversalAdditionalCameraData()
            .scriptableRenderer.EnqueuePass(blurRenderPass);
    }
}

```

# 后处理与全屏效果

Unity提供了很多后处理和屏幕效果，可以用来模拟物理摄像机和电影效果，或创建风格化的视觉效果。

通用渲染管线内置了后处理效果的实现，其使用Volume框架，以下内容均基于URP。

后处理效果会非常耗时，在默认情况下，以下效果对于移动设备是最友好的：

- Bloom（禁用高质量过滤）
- Chromatic Aberration
- Color Grading
- Lens Distortion
- Vignette

对于Depth of filed，建议在低端设备上使用Gausian。

## 添加后处理

新的场景默认不会使用后处理，因此必须手动添加，然后逐个配置以达到预期效果。

1. 选择一个摄像机，在Inspector窗口中启动Post Processing
2. 在场景中创建一个游戏对象并添加Volume组件，GameObject>Volume>Global Volume
3. 选择游戏对象，在Volume组件上点击New，创建一个Volume Profile
4. 点击Add Override，然后选择需要的后处理效果

## Volumes

### 理解Volumes

URP使用Volume实现后处理效果，Volume能够根据与摄像机的距离来覆盖或扩展场景属性。

可以创建以下专用的Volume游戏对象：

- Global Volume
- Box Volume
- Sphere Volume
- Convex Mesh Volume

一个场景可以多个带有Volume组件的游戏对象，一个游戏对象可以附加多个Volume组件。

在运行时，URP会遍历场景上激活的Volume，使用摄像机位置和Volume组件属性来计算每一个Volume对最终场景设置的贡献。

URP会对所有非零的Volume贡献值进行插值，计算出最终的属性值。

#### 全局和局部Volume

全局Volume会影响场景上所有的摄像机，局部Volume只会影响处处于Volume碰撞体范围中的摄像机。

#### Volume Profiles和Volume Overrides

每一个Volume组件都会引用一个Volume Profile，其包含了在位于多个Volume Overrides中场景属性，每一个Volume Override控制不同的设置。

#### 默认的volumes

- 整个项目的默认Volume，使用Project Settings>Graphics>URR>Default Volume Profile的设置
- 当前品质的全局Volume，使用激活的URP Asset>Volumes>Volume Profile的设置

URP只会在第一次加载场景或当你改变品质级别时才会评估默认volumes，而非每帧。

## 自定义后处理

### 使用Full Screen Render Pass Renderer Feature

1. 利用实现后处理效果的Shader创建一个材质
2. 选择URP Renderer，在Inspector中点击Add Renderer Feature，选择Full Screen Pass Renderer Feature
3. 将材质设置到Pass Material
4. 其他设置

### 创建支持Volume的自定义后处理效果

URP提供了自定义后处理效果的模板，通过Assets>Create>Rendering>URP Post-processing Effect(Renderer Feature with Volume)创建。

Unity会创建两个脚本模板，一个关于Renderer Feature，另一个关于Volume组件，模板包含了反转屏幕颜色的效果实现。

Renderer Feature脚本包含了ScriptableRenderPass的实现，在Create方法中定义了自定义效果的材质或实现了效果逻辑的Render Pass。

PASS_SHARED_RENDERING_CODE区域负责设置自定义效果的着色器属性。

PASS_RENDER_GRAPH_PATH区域使用的是渲染图API，在兼容模式为禁用时Unity选择使用PASS_NON_RENDER_GRAPH_PATH区域的代码。

为了设置Volume组件的效果属性，可以修改AddRenderPasses方法中的以下代码：

```CS
NewPostProcessEffectVolumeComponent myVolume = VolumeManager.instance.stack?.GetComponent<NewPostProcessEffectVolumeComponent>(); if (myVolume == null || !myVolume.IsActive()) s_SharedPropertyBlock.SetFloat("_Intensity", myVolume.intensity.value);
```